{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet d'import des données Historique Zendesk vers BigQuery\n",
    "\n",
    "## Introduction\n",
    "1. Imports des bibliothèques nécessaires\n",
    "2. Définition des variables et des configurations\n",
    "3. Manipulation des données JSON\n",
    "4. Création des fonctions pour le chargement des données\n",
    "5. Exécution du processus de chargement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Début du chargement des bibliothèques ...\n",
      "... Bibliothèques chargées ...\n"
     ]
    }
   ],
   "source": [
    "print(\"... Début du chargement des bibliothèques ...\")\n",
    "import json                         # Manipulation JSON -> Déjà prévu dans Python\n",
    "import pandas as pd                 # Manipulation données -> pip install pandas\n",
    "\n",
    "#instalation Gcoud CLI + créer des id locaux pour mon compte Google\n",
    "# Documentations :\n",
    "# - https://cloud.google.com/bigquery/docs/authentication?hl=fr\n",
    "# - https://cloud.google.com/sdk/docs/install?hl=fr\n",
    "# - https://cloud.google.com/bigquery/docs/authentication/getting-started?hl=fr\n",
    "\n",
    "from google.cloud import bigquery   # Liaison BigQuery -> pip install google-cloud-bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud.exceptions import NotFound\n",
    "import os\n",
    "print(\"... Bibliothèques chargées ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Variables et configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fichiers JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportZendesk1 = 'file1.json'   # Export\n",
    "exportZendesk2 = 'file2.json'   # Données en base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#project_id = \"your_projectID\"                          # Identifiant du projet BigQuery\n",
    "#dataset_id = \"your_datasetID\"                  # Identifiant du dataset BigQuery\n",
    "#table_name = \"your_tablename\"                                   # Nom de la table de destination\n",
    "#json_file_path = \"your_path\"                     # Chemin d'accès à l'export JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Manipulation données JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge des 2 fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"... Ouverture du premier fichier en cours ...\")\n",
    "with open(exportZendesk1) as f:  \n",
    "    data1 = json.load(f)\n",
    "print(\"... Premier fichier ouvert ...\")  \n",
    "\n",
    "print(\"... Ouverture du deuxième fichier en cours ...\")  \n",
    "with open(exportZendesk2) as f:  \n",
    "    data2 = json.load(f)\n",
    "print(\"... Deuxième fichier ouvert ...\")  \n",
    "\n",
    "print(\"... Fusion des 2 fichiers ...\")\n",
    "data1.update(data2)\n",
    "print(\"... Fusion terminé ...\")\n",
    "\n",
    "print(\"... écriture du nouveau fichier ...\")\n",
    "with open('merged.json', 'w') as f:  \n",
    "    json.dump(data1, f)\n",
    "print(\"... écriture du nouveau fichier terminé ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérification et suppression des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fonctions (chargement et insertion des données)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Initialisation du client BigQuery ...\n",
      "... Initialisation terminé\n",
      "Dataset syncari found.\n",
      "Table zd_tickets found.\n",
      "... Confirguration ...\n",
      "... Configuration terminé ...\n",
      "... Début du chargement des données ...\n"
     ]
    },
    {
     "ename": "Forbidden",
     "evalue": "403 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/lumapps-internal-bi/jobs?uploadType=resumable: Access Denied: Dataset lumapps-internal-bi:syncari: Permission bigquery.tables.create denied on dataset lumapps-internal-bi:syncari (or it may not exist).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidResponse\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Robin N\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:2580\u001b[0m, in \u001b[0;36mClient.load_table_from_file\u001b[1;34m(self, file_obj, destination, rewind, size, num_retries, job_id, job_id_prefix, location, project, job_config, timeout)\u001b[0m\n\u001b[0;32m   2579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m _MAX_MULTIPART_SIZE:\n\u001b[1;32m-> 2580\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_resumable_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_resource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\n\u001b[0;32m   2582\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Robin N\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:3000\u001b[0m, in \u001b[0;36mClient._do_resumable_upload\u001b[1;34m(self, stream, metadata, num_retries, timeout, project)\u001b[0m\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Perform a resumable upload.\u001b[39;00m\n\u001b[0;32m   2978\u001b[0m \n\u001b[0;32m   2979\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2998\u001b[0m \u001b[38;5;124;03m    is uploaded.\u001b[39;00m\n\u001b[0;32m   2999\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3000\u001b[0m upload, transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initiate_resumable_upload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\n\u001b[0;32m   3002\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3004\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m upload\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[1;32mc:\\Users\\Robin N\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:3069\u001b[0m, in \u001b[0;36mClient._initiate_resumable_upload\u001b[1;34m(self, stream, metadata, num_retries, timeout, project)\u001b[0m\n\u001b[0;32m   3065\u001b[0m     upload\u001b[38;5;241m.\u001b[39m_retry_strategy \u001b[38;5;241m=\u001b[39m resumable_media\u001b[38;5;241m.\u001b[39mRetryStrategy(\n\u001b[0;32m   3066\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39mnum_retries\n\u001b[0;32m   3067\u001b[0m     )\n\u001b[1;32m-> 3069\u001b[0m \u001b[43mupload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitiate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3070\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3072\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3073\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_GENERIC_CONTENT_TYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3074\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_final\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3076\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3078\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m upload, transport\n",
      "File \u001b[1;32mc:\\Users\\Robin N\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\resumable_media\\requests\\upload.py:420\u001b[0m, in \u001b[0;36mResumableUpload.initiate\u001b[1;34m(self, transport, stream, metadata, content_type, total_bytes, stream_final, timeout)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_and_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriable_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_strategy\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robin N\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\resumable_media\\requests\\_request_helpers.py:155\u001b[0m, in \u001b[0;36mwait_and_retry\u001b[1;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _CONNECTION_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Robin N\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\resumable_media\\requests\\upload.py:416\u001b[0m, in \u001b[0;36mResumableUpload.initiate.<locals>.retriable_request\u001b[1;34m()\u001b[0m\n\u001b[0;32m    412\u001b[0m result \u001b[38;5;241m=\u001b[39m transport\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    413\u001b[0m     method, url, data\u001b[38;5;241m=\u001b[39mpayload, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    414\u001b[0m )\n\u001b[1;32m--> 416\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_initiate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Robin N\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\resumable_media\\_upload.py:518\u001b[0m, in \u001b[0;36mResumableUpload._process_initiate_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process the response from an HTTP request that initiated upload.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \n\u001b[0;32m    505\u001b[0m \u001b[38;5;124;03mThis is everything that must be done after a request that doesn't\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;124;03m.. _sans-I/O: https://sans-io.readthedocs.io/\u001b[39;00m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 518\u001b[0m \u001b[43m_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_status_code\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCREATED\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_invalid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resumable_url \u001b[38;5;241m=\u001b[39m _helpers\u001b[38;5;241m.\u001b[39mheader_required(\n\u001b[0;32m    525\u001b[0m     response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_headers\n\u001b[0;32m    526\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Robin N\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\resumable_media\\_helpers.py:108\u001b[0m, in \u001b[0;36mrequire_status_code\u001b[1;34m(response, status_codes, get_status_code, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m         callback()\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m common\u001b[38;5;241m.\u001b[39mInvalidResponse(\n\u001b[0;32m    109\u001b[0m         response,\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest failed with status code\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    111\u001b[0m         status_code,\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected one of\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;241m*\u001b[39mstatus_codes\n\u001b[0;32m    114\u001b[0m     )\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m status_code\n",
      "\u001b[1;31mInvalidResponse\u001b[0m: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.CREATED: 201>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... Début du chargement des données ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m source_file:                                           \u001b[38;5;66;03m# rb = read binary => meilleur compatibilité et intégrité des données\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     load_job \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_table_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m load_job\u001b[38;5;241m.\u001b[39mresult()                                                                           \u001b[38;5;66;03m# Attendre la fin du job de chargement\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... Chargement des données terminé ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Robin N\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\cloud\\bigquery\\client.py:2588\u001b[0m, in \u001b[0;36mClient.load_table_from_file\u001b[1;34m(self, file_obj, destination, rewind, size, num_retries, job_id, job_id_prefix, location, project, job_config, timeout)\u001b[0m\n\u001b[0;32m   2584\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_multipart_upload(\n\u001b[0;32m   2585\u001b[0m             file_obj, job_resource, size, num_retries, timeout, project\u001b[38;5;241m=\u001b[39mproject\n\u001b[0;32m   2586\u001b[0m         )\n\u001b[0;32m   2587\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mInvalidResponse \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m-> 2588\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_http_response(exc\u001b[38;5;241m.\u001b[39mresponse)\n\u001b[0;32m   2590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mcast(LoadJob, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_from_resource(response\u001b[38;5;241m.\u001b[39mjson()))\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/upload/bigquery/v2/projects/lumapps-internal-bi/jobs?uploadType=resumable: Access Denied: Dataset lumapps-internal-bi:syncari: Permission bigquery.tables.create denied on dataset lumapps-internal-bi:syncari (or it may not exist)."
     ]
    }
   ],
   "source": [
    "# Initialisation du client BigQuery avec une clé de compte de service\n",
    "print(\"... Initialisation du client BigQuery ...\")\n",
    "#client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "#credentials = service_account.Credentials.from_service_account_file(credentials_path)\n",
    "client = bigquery.Client(project=project_id)\n",
    "print(\"... Initialisation terminé\")\n",
    "\n",
    "# Référence au dataset et à la table\n",
    "dataset_ref = client.dataset(dataset_id)\n",
    "table_ref = dataset_ref.table(table_name)\n",
    "\n",
    "# Vérification de l'existence du dataset\n",
    "try:\n",
    "    client.get_dataset(dataset_ref)\n",
    "    print(f\"Dataset {dataset_id} found.\")\n",
    "except NotFound:\n",
    "    print(f\"Dataset {dataset_id} not found.\")\n",
    "    exit(1)\n",
    "\n",
    "# Vérification de l'existence de la table\n",
    "try:\n",
    "    client.get_table(table_ref)\n",
    "    print(f\"Table {table_name} found.\")\n",
    "except NotFound:\n",
    "    print(f\"Table {table_name} not found. Creating table schema.\")\n",
    "\n",
    "# Configuration du job de chargement\n",
    "print(\"... Confirguration ...\")\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.NEWLINE_DELIMITED_JSON\n",
    "job_config.write_disposition = bigquery.WriteDisposition.WRITE_APPEND\n",
    "print(\"... Configuration terminé ...\")\n",
    "\n",
    "# Chargement des données JSON dans la table BigQuery\n",
    "print(\"... Début du chargement des données ...\")\n",
    "with open(json_file_path, \"rb\") as source_file:                                           # rb = read binary => meilleur compatibilité et intégrité des données\n",
    "    load_job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "load_job.result()                                                                           # Attendre la fin du job de chargement\n",
    "print(\"... Chargement des données terminé ...\")\n",
    "\n",
    "print(f\"Les données du fichier {json_file_path} ont été chargées avec succès dans {table_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
